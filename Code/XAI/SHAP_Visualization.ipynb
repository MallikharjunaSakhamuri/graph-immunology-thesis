{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f019c6f6",
      "metadata": {
        "id": "f019c6f6"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow[and-cuda]\n",
        "# !pip install numpy==1.24.3 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e29e96",
      "metadata": {
        "id": "56e29e96"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd4938d",
      "metadata": {
        "id": "3fd4938d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import shap\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool, MessagePassing\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from torch_geometric.data import Data\n",
        "from rdkit.Chem import RemoveHs\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "from rdkit import RDLogger\n",
        "# Suppress RDKit warnings\n",
        "RDLogger.DisableLog('rdApp.warning')\n",
        "import tensorflow as tensorflow\n",
        "import traceback\n",
        "import os\n",
        "from datetime import datetime\n",
        "from rdkit.Chem import rdDepictor\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit.Chem import AllChem, Draw, rdDepictor\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "class GraphDiscriminator(nn.Module):\n",
        "    \"\"\"Reimplementation of original discriminator architecture\"\"\"\n",
        "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim: int = 128, output_dim: int = 128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature encoding\n",
        "        self.node_encoder = nn.Sequential(\n",
        "            nn.Linear(node_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.edge_encoder = nn.Sequential(\n",
        "            nn.Linear(edge_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Graph convolution layers\n",
        "        self.conv1 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "        # Projection head\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(output_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = torch.cat([data.x_cat.float(), data.x_phys], dim=-1)\n",
        "        edge_index = data.edge_index\n",
        "        edge_attr = data.edge_attr.float()\n",
        "        batch = data.batch\n",
        "\n",
        "        # Initial feature encoding\n",
        "        x = self.node_encoder(x)\n",
        "        edge_attr = self.edge_encoder(edge_attr)\n",
        "\n",
        "        # Graph convolutions\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # Projection\n",
        "        x = self.projection(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load Encoder\n",
        "def load_encoder(model_path, device='cpu'):\n",
        "    \"\"\"Load trained encoder\"\"\"\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    encoder = GraphDiscriminator(\n",
        "        node_dim=checkpoint['model_info'].get('node_dim'),\n",
        "        edge_dim=checkpoint['model_info'].get('edge_dim'),\n",
        "        hidden_dim=checkpoint['model_info'].get('hidden_dim', 128),\n",
        "        output_dim=checkpoint['model_info'].get('output_dim', 128)\n",
        "    )\n",
        "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "    encoder.eval()\n",
        "    return encoder.to(device)\n",
        "\n",
        "# Load Embeddings\n",
        "def load_embeddings(filepath):\n",
        "    \"\"\"Load embeddings and labels\"\"\"\n",
        "    with open(filepath, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data['embeddings'], data['labels']\n",
        "\n",
        "# Paths from your saved model\n",
        "encoder_path = './checkpoints/encoders/final_encoder_20250216_111050.pt'\n",
        "embedding_path = './embeddings/final_embeddings_20250216_111005.pkl'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Load encoder and embeddings\n",
        "encoder = load_encoder(encoder_path, device)\n",
        "embeddings, graph_data = load_embeddings(embedding_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044b2c1f",
      "metadata": {
        "id": "044b2c1f"
      },
      "outputs": [],
      "source": [
        "class MolecularFeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.atom_list = list(range(1, 119))\n",
        "        self.chirality_list = [\n",
        "            Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
        "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
        "            Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
        "            Chem.rdchem.ChiralType.CHI_OTHER\n",
        "        ]\n",
        "        self.bond_list = [\n",
        "            Chem.rdchem.BondType.SINGLE,\n",
        "            Chem.rdchem.BondType.DOUBLE,\n",
        "            Chem.rdchem.BondType.TRIPLE,\n",
        "            Chem.rdchem.BondType.AROMATIC\n",
        "        ]\n",
        "        self.bonddir_list = [\n",
        "            Chem.rdchem.BondDir.NONE,\n",
        "            Chem.rdchem.BondDir.ENDUPRIGHT,\n",
        "            Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
        "        ]\n",
        "\n",
        "    def calc_atom_features(self, atom: Chem.Atom) -> Tuple[list, list]:\n",
        "        \"\"\"Calculate atom features with better error handling\"\"\"\n",
        "        try:\n",
        "            # Basic features\n",
        "            atom_feat = [\n",
        "                self.atom_list.index(atom.GetAtomicNum()),\n",
        "                self.chirality_list.index(atom.GetChiralTag())\n",
        "            ]\n",
        "\n",
        "            # Physical features with error handling\n",
        "            phys_feat = []\n",
        "\n",
        "            # Molecular weight contribution\n",
        "            try:\n",
        "                contrib_mw = Descriptors.ExactMolWt(Chem.MolFromSmiles(f'[{atom.GetSymbol()}]'))\n",
        "                phys_feat.append(contrib_mw)\n",
        "            except:\n",
        "                phys_feat.append(0.0)\n",
        "\n",
        "            # LogP contribution\n",
        "            try:\n",
        "                contrib_logp = Descriptors.MolLogP(Chem.MolFromSmiles(f'[{atom.GetSymbol()}]'))\n",
        "                phys_feat.append(contrib_logp)\n",
        "            except:\n",
        "                phys_feat.append(0.0)\n",
        "\n",
        "            # Add other physical properties\n",
        "            phys_feat.extend([\n",
        "                atom.GetFormalCharge(),\n",
        "                int(atom.GetHybridization()),\n",
        "                int(atom.GetIsAromatic()),\n",
        "                atom.GetTotalNumHs(),\n",
        "                atom.GetTotalValence(),\n",
        "                atom.GetDegree()\n",
        "            ])\n",
        "\n",
        "            return atom_feat, phys_feat\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating atom features: {e}\")\n",
        "            return [0, 0], [0.0] * 9\n",
        "\n",
        "    def get_atom_features(self, mol: Chem.Mol) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Extract atom features for the whole molecule\"\"\"\n",
        "        atom_feats = []\n",
        "        phys_feats = []\n",
        "\n",
        "        if mol is None:\n",
        "            return torch.tensor([[0, 0]], dtype=torch.long), torch.tensor([[0.0] * 9], dtype=torch.float)\n",
        "\n",
        "        for atom in mol.GetAtoms():\n",
        "            atom_feat, phys_feat = self.calc_atom_features(atom)\n",
        "            atom_feats.append(atom_feat)\n",
        "            phys_feats.append(phys_feat)\n",
        "\n",
        "        x = torch.tensor(atom_feats, dtype=torch.long)\n",
        "        phys = torch.tensor(phys_feats, dtype=torch.float)\n",
        "\n",
        "        return x, phys\n",
        "\n",
        "    def remove_unbonded_hydrogens(mol):\n",
        "        params = Chem.RemoveHsParameters()\n",
        "        params.removeDegreeZero = True\n",
        "        mol = Chem.RemoveHs(mol, params)\n",
        "        return mol\n",
        "\n",
        "\n",
        "    def get_bond_features(self, mol: Chem.Mol) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Extract bond features with better error handling\"\"\"\n",
        "        if mol is None:\n",
        "            return torch.tensor([[0], [0]], dtype=torch.long), torch.tensor([[0.0] * 5], dtype=torch.float)\n",
        "\n",
        "        row, col, edge_feat = [], [], []\n",
        "\n",
        "        for bond in mol.GetBonds():\n",
        "            try:\n",
        "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "\n",
        "                # Add edges in both directions\n",
        "                row += [start, end]\n",
        "                col += [end, start]\n",
        "\n",
        "                # Bond features\n",
        "                bond_type = self.bond_list.index(bond.GetBondType())\n",
        "                bond_dir = self.bonddir_list.index(bond.GetBondDir())\n",
        "\n",
        "                # Calculate additional properties\n",
        "                feat = [\n",
        "                    bond_type,\n",
        "                    bond_dir,\n",
        "                    int(bond.GetIsConjugated()),\n",
        "                    int(self._is_rotatable(bond)),\n",
        "                    self._get_bond_length(mol, start, end)\n",
        "                ]\n",
        "\n",
        "                edge_feat.extend([feat, feat])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing bond: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not row:  # If no valid bonds were processed\n",
        "            return torch.tensor([[0], [0]], dtype=torch.long), torch.tensor([[0.0] * 5], dtype=torch.float)\n",
        "\n",
        "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "        edge_attr = torch.tensor(edge_feat, dtype=torch.float)\n",
        "\n",
        "        return edge_index, edge_attr\n",
        "\n",
        "    def _is_rotatable(self, bond: Chem.Bond) -> bool:\n",
        "        \"\"\"Check if bond is rotatable\"\"\"\n",
        "        return (bond.GetBondType() == Chem.rdchem.BondType.SINGLE and\n",
        "                not bond.IsInRing() and\n",
        "                len(bond.GetBeginAtom().GetNeighbors()) > 1 and\n",
        "                len(bond.GetEndAtom().GetNeighbors()) > 1)\n",
        "\n",
        "    def _get_bond_length(self, mol: Chem.Mol, start: int, end: int) -> float:\n",
        "        \"\"\"Get bond length with error handling\"\"\"\n",
        "        try:\n",
        "            conf = mol.GetConformer()\n",
        "            if conf.Is3D():\n",
        "                return Chem.rdMolTransforms.GetBondLength(conf, start, end)\n",
        "        except:\n",
        "            pass\n",
        "        return 0.0\n",
        "\n",
        "    def process_molecule(self, smiles: str) -> Data:\n",
        "        \"\"\"Process SMILES string to graph data\"\"\"\n",
        "        try:\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            if mol is None:\n",
        "                print(f\"Invalid SMILES: {smiles}\")\n",
        "                return None  # Skip invalid molecules\n",
        "            mol = RemoveHs(mol)\n",
        "\n",
        "            # Add explicit hydrogens\n",
        "            mol = Chem.AddHs(mol, addCoords=True)\n",
        "\n",
        "            # Sanitize molecule\n",
        "            Chem.SanitizeMol(mol)\n",
        "\n",
        "            # Check if the molecule has atoms\n",
        "            if mol.GetNumAtoms() == 0:\n",
        "                print(\"Molecule has no atoms, skipping.\")\n",
        "                return None\n",
        "\n",
        "            # Generate 3D coordinates\n",
        "            if not mol.GetNumConformers():\n",
        "                status = AllChem.EmbedMolecule(mol, AllChem.ETKDG())\n",
        "                if status != 0:\n",
        "                    print(\"Failed to generate 3D conformer\")\n",
        "                    return None  # Skip failed molecules\n",
        "\n",
        "                # Try MMFF or UFF optimization\n",
        "                try:\n",
        "                    AllChem.MMFFOptimizeMolecule(mol)\n",
        "                except:\n",
        "                    AllChem.UFFOptimizeMolecule(mol)\n",
        "\n",
        "            # Extract features\n",
        "            x_cat, x_phys = self.get_atom_features(mol)\n",
        "            edge_index, edge_attr = self.get_bond_features(mol)\n",
        "\n",
        "            return Data(\n",
        "                x_cat=x_cat,\n",
        "                x_phys=x_phys,\n",
        "                edge_index=edge_index,\n",
        "                edge_attr=edge_attr,\n",
        "                num_nodes=x_cat.size(0)\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing molecule {smiles}: {e}\")\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c661bed",
      "metadata": {
        "id": "0c661bed"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.data import Batch, Data\n",
        "from typing import List, Tuple\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "class GraphModelWrapper:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.model.eval()\n",
        "        self.original_x_cat = None\n",
        "        self.original_x_phys = None\n",
        "        self.batch = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        \"\"\"\n",
        "        Custom call method to handle graph data\n",
        "        features: feature matrix (numpy array)\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            if isinstance(features, np.ndarray):\n",
        "                features = torch.tensor(features, dtype=torch.float).to(self.device)\n",
        "\n",
        "            # Get original shapes\n",
        "            num_nodes = self.original_x_cat.size(0)\n",
        "            num_cat_features = self.original_x_cat.size(1)\n",
        "\n",
        "            # Reshape features to match original dimensions\n",
        "            x_cat = features.reshape(num_nodes, num_cat_features).to(torch.long)\n",
        "\n",
        "            # Create a new batch with modified features\n",
        "            new_data = Data(\n",
        "                x_cat=x_cat,\n",
        "                x_phys=self.original_x_phys,\n",
        "                edge_index=self.batch.edge_index,\n",
        "                edge_attr=self.batch.edge_attr,\n",
        "                batch=self.batch.batch if hasattr(self.batch, 'batch') else None\n",
        "            )\n",
        "\n",
        "            # Get model output\n",
        "            outputs = self.model(new_data)\n",
        "            return outputs.cpu().numpy()\n",
        "\n",
        "class ModifiedGraphWrapper:\n",
        "    def __init__(self, model, device, batch):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.original_batch = batch\n",
        "        self.model.eval()\n",
        "        self.num_nodes = batch.x_cat.shape[0]\n",
        "        self.num_features = batch.x_cat.shape[1]\n",
        "        self.num_phys_features = batch.x_phys.shape[1]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                # Convert input to tensor\n",
        "                x = torch.tensor(x, dtype=torch.float).to(self.device)\n",
        "\n",
        "                # Reshape x to match the expected input shape\n",
        "                if len(x.shape) == 1:\n",
        "                    x = x.reshape(1, self.num_nodes, self.num_features)\n",
        "                else:\n",
        "                    x = x.reshape(-1, self.num_nodes, self.num_features)\n",
        "\n",
        "                print(f\"Processing batch of size {x.shape[0]}\")\n",
        "\n",
        "                all_results = []\n",
        "                for idx in range(x.shape[0]):\n",
        "                    # Extract categorical features\n",
        "                    x_cat = x[idx].to(torch.long)\n",
        "\n",
        "                    # Ensure proper dimensions for x_cat and x_phys\n",
        "                    if len(x_cat.shape) == 2:\n",
        "                        x_cat = x_cat.unsqueeze(0)\n",
        "                    x_phys = self.original_batch.x_phys.unsqueeze(0)\n",
        "\n",
        "                    # Create consistent batch dimension\n",
        "                    batch_idx = torch.zeros(self.num_nodes, dtype=torch.long, device=self.device)\n",
        "\n",
        "                    # Create data object for this sample\n",
        "                    new_data = Data(\n",
        "                        x_cat=x_cat.squeeze(0),\n",
        "                        x_phys=x_phys.squeeze(0),\n",
        "                        edge_index=self.original_batch.edge_index,\n",
        "                        edge_attr=self.original_batch.edge_attr,\n",
        "                        batch=batch_idx,\n",
        "                        num_nodes=self.num_nodes\n",
        "                    ).to(self.device)\n",
        "\n",
        "                    # Get node features\n",
        "                    node_features = torch.cat([new_data.x_cat.float(), new_data.x_phys], dim=-1)\n",
        "                    x_encoded = self.model.node_encoder(node_features)\n",
        "\n",
        "                    # Get intermediate representations\n",
        "                    x1 = F.relu(self.model.conv1(x_encoded, new_data.edge_index))\n",
        "                    x2 = F.relu(self.model.conv2(x1, new_data.edge_index))\n",
        "                    x3 = self.model.conv3(x2, new_data.edge_index)\n",
        "\n",
        "                    # Combine representations from different layers\n",
        "                    combined_features = torch.stack([x1, x2, x3], dim=0)\n",
        "                    node_embeddings = torch.mean(combined_features, dim=0)\n",
        "\n",
        "                    # Compute node importance\n",
        "                    node_importance = torch.norm(node_embeddings, dim=1).cpu().numpy()\n",
        "                    all_results.append(node_importance)\n",
        "\n",
        "                result = np.array(all_results)\n",
        "                print(f\"Result shape: {result.shape}\")\n",
        "                return result\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in model wrapper: {e}\")\n",
        "                print(f\"Debug info:\")\n",
        "                print(f\"x shape: {x.shape}\")\n",
        "                if 'node_features' in locals():\n",
        "                    print(f\"node_features shape: {node_features.shape}\")\n",
        "                if 'node_embeddings' in locals():\n",
        "                    print(f\"node_embeddings shape: {node_embeddings.shape}\")\n",
        "                raise\n",
        "\n",
        "def explain_graph_model(model, graph_data, device, num_samples=100):\n",
        "    \"\"\"Generate SHAP explanations for graph neural network\"\"\"\n",
        "    batch = Batch.from_data_list([graph_data]).to(device)\n",
        "\n",
        "    # Initialize wrapper\n",
        "    model_wrapper = ModifiedGraphWrapper(model, device, batch)\n",
        "\n",
        "    # Create background data\n",
        "    background = batch.x_cat.cpu().numpy().astype(float)\n",
        "    background_flat = background.reshape(-1)\n",
        "\n",
        "    # Generate background samples\n",
        "    n_background = 50\n",
        "    background_samples = []\n",
        "    for _ in range(n_background):\n",
        "        perturbed = background_flat.copy()\n",
        "        noise = np.random.normal(0, 0.3, perturbed.shape)\n",
        "        perturbed = np.clip(perturbed + noise, 0, None)\n",
        "        background_samples.append(perturbed)\n",
        "\n",
        "    background_matrix = np.stack(background_samples)\n",
        "    print(f\"Background matrix shape: {background_matrix.shape}\")\n",
        "\n",
        "    try:\n",
        "        # Test run\n",
        "        test_output = model_wrapper(background_matrix[0:1])\n",
        "        print(f\"Test output shape: {test_output.shape}\")\n",
        "\n",
        "        # Initialize explainer\n",
        "        explainer = shap.KernelExplainer(\n",
        "            model_wrapper,\n",
        "            background_matrix,\n",
        "            link=\"identity\",\n",
        "            feature_perturbation=\"interventional\"\n",
        "        )\n",
        "\n",
        "        # Calculate SHAP values\n",
        "        shap_values = explainer.shap_values(\n",
        "            background_flat,\n",
        "            nsamples=200,\n",
        "            l1_reg=\"num_features(10)\",\n",
        "            silent=True\n",
        "        )\n",
        "\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_values = np.array(shap_values)\n",
        "\n",
        "        print(f\"Raw SHAP values shape: {shap_values.shape}\")\n",
        "\n",
        "        # Process SHAP values to get node importance\n",
        "        # Sum absolute SHAP values across all features for each node\n",
        "        num_nodes = batch.x_cat.shape[0]\n",
        "        node_importance = np.zeros(num_nodes)\n",
        "\n",
        "        # Aggregate SHAP values per node\n",
        "        features_per_node = batch.x_cat.shape[1]  # number of features per node\n",
        "        for i in range(num_nodes):\n",
        "            start_idx = i * features_per_node\n",
        "            end_idx = (i + 1) * features_per_node\n",
        "            node_importance[i] = np.abs(shap_values[start_idx:end_idx]).sum()\n",
        "\n",
        "        # Normalize importance scores\n",
        "        node_importance = (node_importance - node_importance.min()) / \\\n",
        "                         (node_importance.max() - node_importance.min() + 1e-10)\n",
        "\n",
        "        print(\"\\nNode importance statistics:\")\n",
        "        print(f\"Shape: {node_importance.shape}\")\n",
        "        print(f\"Range: {node_importance.min():.6f} to {node_importance.max():.6f}\")\n",
        "        print(f\"Mean: {node_importance.mean():.6f}\")\n",
        "        print(f\"Std: {node_importance.std():.6f}\")\n",
        "\n",
        "        # Print top 5 most important nodes\n",
        "        sorted_indices = np.argsort(node_importance)[::-1]\n",
        "        print(\"\\nTop 5 most important nodes:\")\n",
        "        for i in range(5):\n",
        "            idx = sorted_indices[i]\n",
        "            print(f\"Node {idx}: {node_importance[idx]:.6f}\")\n",
        "\n",
        "        return node_importance, shap_values\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in SHAP calculation: {e}\")\n",
        "        print(f\"Debug info:\")\n",
        "        print(f\"- Background matrix shape: {background_matrix.shape}\")\n",
        "        print(f\"- Number of nodes: {batch.x_cat.shape[0]}\")\n",
        "        print(f\"- Feature dimension: {batch.x_cat.shape[1]}\")\n",
        "        if 'shap_values' in locals():\n",
        "            print(f\"- SHAP values shape: {shap_values.shape}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def visualize_molecule_with_importance(smiles, node_importance, save_path=None):\n",
        "    \"\"\"\n",
        "    Create a figure with both molecular visualization and bar plot of importance scores\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import AllChem, Draw\n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "    import numpy as np\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        print(f\"Could not parse SMILES: {smiles}\")\n",
        "        return None\n",
        "\n",
        "    num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14),\n",
        "                                  gridspec_kw={'height_ratios': [1.5, 1]})\n",
        "\n",
        "    # 1. Molecular Visualization\n",
        "    atom_colors = {}\n",
        "    atom_info = []\n",
        "\n",
        "    # Ensure importance scores are normalized to [0,1]\n",
        "    normalized_scores = (node_importance - node_importance.min()) / \\\n",
        "                       (node_importance.max() - node_importance.min())\n",
        "\n",
        "    # Custom color map for better visibility\n",
        "    def get_color(score):\n",
        "        \"\"\"Generate color based on importance score with more distinct gradients\"\"\"\n",
        "        if score > 0.8:\n",
        "            return (0.8, 0.0, 0.0)  # Deep red\n",
        "        elif score > 0.6:\n",
        "            return (1.0, 0.2, 0.2)  # Medium-deep red\n",
        "        elif score > 0.4:\n",
        "            return (1.0, 0.5, 0.5)  # Medium red\n",
        "        elif score > 0.3:\n",
        "            return (1.0, 0.7, 0.7)  # Light-medium red\n",
        "        elif score > 0.2:\n",
        "            return (1.0, 0.85, 0.85)  # Light red\n",
        "        else:\n",
        "            return (1.0, 0.95, 0.95)  # Very light red/almost white\n",
        "\n",
        "    # Generate 2D coordinates if they don't exist\n",
        "    if mol.GetNumConformers() == 0:\n",
        "        AllChem.Compute2DCoords(mol)\n",
        "\n",
        "    # Create highlighting details\n",
        "    highlight_atoms = []\n",
        "    highlight_colors = {}\n",
        "    atom_labels = {}\n",
        "\n",
        "    for i in range(num_atoms):\n",
        "        atom = mol.GetAtomWithIdx(i)\n",
        "        importance = normalized_scores[i]\n",
        "        atom_info.append((i, atom.GetSymbol(), importance))\n",
        "\n",
        "        # Add to highlighting\n",
        "        highlight_atoms.append(i)\n",
        "        highlight_colors[i] = get_color(importance)\n",
        "\n",
        "        # Create detailed atom label with symbol and index\n",
        "        atom_labels[i] = f\"{atom.GetSymbol()}{i}\"\n",
        "\n",
        "    # Draw the molecule with enhanced settings\n",
        "    d2d = Draw.MolDraw2DCairo(800, 800)\n",
        "    d2d.drawOptions().addAtomIndices = True\n",
        "    d2d.drawOptions().additionalAtomLabelPadding = 0.25\n",
        "    d2d.drawOptions().bondLineWidth = 2.0\n",
        "    d2d.drawOptions().padding = 0.2\n",
        "\n",
        "    # Convert highlight colors to the format RDKit expects\n",
        "    highlight_colors_map = {}\n",
        "    for idx, color in highlight_colors.items():\n",
        "        highlight_colors_map[idx] = color\n",
        "\n",
        "    # Draw molecule\n",
        "    d2d.DrawMolecule(\n",
        "        mol,\n",
        "        highlightAtoms=highlight_atoms,\n",
        "        highlightAtomColors=highlight_colors_map\n",
        "    )\n",
        "    d2d.FinishDrawing()\n",
        "\n",
        "    # Convert to PIL Image\n",
        "    import io\n",
        "    from PIL import Image\n",
        "    png = d2d.GetDrawingText()\n",
        "    img = Image.open(io.BytesIO(png))\n",
        "\n",
        "    # Show molecule in first subplot\n",
        "    ax1.imshow(img)\n",
        "    ax1.axis('off')\n",
        "    ax1.set_title('Molecular Structure with SHAP Importance\\nRed intensity indicates importance',\n",
        "                  pad=20, fontsize=14)\n",
        "\n",
        "    # 2. Bar Plot\n",
        "    # Sort atoms by importance\n",
        "    atom_info.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create bar plot\n",
        "    indices, symbols, scores = zip(*atom_info)\n",
        "    atom_labels = [f\"{symbols[i]}{indices[i]}\" for i in range(len(indices))]\n",
        "\n",
        "    bars = ax2.bar(range(len(scores)), scores)\n",
        "\n",
        "    # Color bars using same gradient\n",
        "    for idx, bar in enumerate(bars):\n",
        "        bar.set_facecolor(get_color(scores[idx]))\n",
        "\n",
        "    # Customize bar plot\n",
        "    ax2.set_xticks(range(len(scores)))\n",
        "    ax2.set_xticklabels(atom_labels, rotation=45, ha='right', fontsize=10)\n",
        "    ax2.set_ylabel('SHAP Importance Score', fontsize=12)\n",
        "    ax2.set_title('Atom-wise SHAP Importance Scores', pad=20, fontsize=14)\n",
        "    ax2.set_ylim(0, 1.05)\n",
        "\n",
        "    # Add grid for easier reading\n",
        "    ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Add legend for color interpretation\n",
        "    legend_text = (\n",
        "        'Color Legend:\\n'\n",
        "        '  Deep Red: Very high importance (>0.8)\\n'\n",
        "        '  Medium-deep Red: High importance (0.6-0.8)\\n'\n",
        "        '  Medium Red: Medium importance (0.4-0.6)\\n'\n",
        "        '  Light-medium Red: Low-medium importance (0.3-0.4)\\n'\n",
        "        '  Light Red: Low importance (0.2-0.3)\\n'\n",
        "        '  Very Light Red: Very low importance (<0.2)'\n",
        "    )\n",
        "    ax2.text(0.02, 0.98, legend_text,\n",
        "             transform=ax2.transAxes,\n",
        "             fontsize=8,\n",
        "             verticalalignment='top',\n",
        "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    return fig\n",
        "\n",
        "def print_atom_mapping(smiles, node_importance):\n",
        "    \"\"\"Print mapping between atom indices and types with their importance scores\"\"\"\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import AllChem\n",
        "    import numpy as np\n",
        "\n",
        "    if node_importance is None:\n",
        "        print(\"Error: No importance scores available\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(f\"Error: Could not parse SMILES: {smiles}\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nAtom Mapping:\")\n",
        "        print(\"Index | Atom | SHAP Score | Normalized Score\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Convert to numpy array if needed\n",
        "        if not isinstance(node_importance, np.ndarray):\n",
        "            node_importance = np.array(node_importance)\n",
        "\n",
        "        # Normalize importance scores\n",
        "        normalized_scores = (node_importance - node_importance.min()) / \\\n",
        "                          (node_importance.max() - node_importance.min())\n",
        "\n",
        "        # Create mapping with both raw and normalized scores\n",
        "        atom_info = []\n",
        "        for i in range(mol.GetNumAtoms()):\n",
        "            atom = mol.GetAtomWithIdx(i)\n",
        "            raw_score = node_importance[i]\n",
        "            norm_score = normalized_scores[i]\n",
        "            atom_info.append((i, atom.GetSymbol(), raw_score, norm_score))\n",
        "\n",
        "        # Sort by normalized importance\n",
        "        atom_info.sort(key=lambda x: x[3], reverse=True)\n",
        "\n",
        "        # Print mapping\n",
        "        for idx, symbol, raw_score, norm_score in atom_info:\n",
        "            print(f\"{idx:5d} | {symbol:4s} | {raw_score:10.4f} | {norm_score:.4f}\")\n",
        "\n",
        "        # Print additional information\n",
        "        print(\"\\nImportance Score Statistics:\")\n",
        "        print(f\"Minimum: {node_importance.min():.4f}\")\n",
        "        print(f\"Maximum: {node_importance.max():.4f}\")\n",
        "        print(f\"Mean: {node_importance.mean():.4f}\")\n",
        "        print(f\"Std Dev: {node_importance.std():.4f}\")\n",
        "\n",
        "        # Print top N most important atoms\n",
        "        N = 5\n",
        "        print(f\"\\nTop {N} Most Important Atoms:\")\n",
        "        for idx, symbol, raw_score, norm_score in atom_info[:N]:\n",
        "            print(f\"Atom {symbol}{idx}: {raw_score:.4f} (normalized: {norm_score:.4f})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in atom mapping: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def visualize_molecule_importance(smiles, node_importance, save_path=None):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "    # Ensure we have the right number of importance scores\n",
        "    if len(node_importance) >= num_atoms:\n",
        "        # Get importance scores for atoms\n",
        "        imp_scores = node_importance[:num_atoms]\n",
        "\n",
        "        # Use percentile-based normalization\n",
        "        min_val = np.percentile(imp_scores, 10)\n",
        "        max_val = np.percentile(imp_scores, 90)\n",
        "\n",
        "        if max_val > min_val:\n",
        "            normalized_scores = (imp_scores - min_val) / (max_val - min_val)\n",
        "            normalized_scores = np.clip(normalized_scores, 0, 1)\n",
        "        else:\n",
        "            normalized_scores = np.zeros_like(imp_scores)\n",
        "\n",
        "        # Apply non-linear scaling to enhance differences\n",
        "#         normalized_scores = np.power(normalized_scores, 0.5)\n",
        "        normalized_scores = np.exp(4 * normalized_scores) / np.exp(4)\n",
        "\n",
        "        # Create atom colors\n",
        "        atom_colors = {}\n",
        "        importance_info = []\n",
        "\n",
        "        for i in range(num_atoms):\n",
        "            atom = mol.GetAtomWithIdx(i)\n",
        "            score = normalized_scores[i]\n",
        "            raw_score = node_importance[i]\n",
        "\n",
        "            if score < 0.3:\n",
        "                color = (1.0, 1.0, 1.0)  # White for low importance\n",
        "            elif score < 0.6:\n",
        "                color = (1.0, 0.7, 0.7)  # Light red for medium importance\n",
        "            else:\n",
        "                color = (1.0, 0.0, 0.0)  # Deep red for high importance\n",
        "\n",
        "            atom_colors[i] = color\n",
        "\n",
        "#             # Enhanced color gradient\n",
        "#             red = min(1.0, score * 1.2)\n",
        "#             white = max(0.0, 1.0 - score * 1.5)\n",
        "#             atom_colors[i] = (1.0, white, white)\n",
        "\n",
        "            importance_info.append((i, atom.GetSymbol(), raw_score, score))\n",
        "\n",
        "        # Sort and print atom importance\n",
        "        importance_info.sort(key=lambda x: x[2], reverse=True)\n",
        "        print(\"\\nAtom Importance Ranking (Top 5):\")\n",
        "        for idx, symbol, raw_score, norm_score in importance_info[:5]:\n",
        "            print(f\"Atom {idx} ({symbol}): raw importance = {raw_score:.6f}, \"\n",
        "                  f\"normalized = {norm_score:.4f}\")\n",
        "\n",
        "        # Generate 2D coordinates\n",
        "        AllChem.Compute2DCoords(mol)\n",
        "\n",
        "        # Create list of bonds to highlight\n",
        "        bonds = []\n",
        "        for bond in mol.GetBonds():\n",
        "            begin_idx = bond.GetBeginAtomIdx()\n",
        "            end_idx = bond.GetEndAtomIdx()\n",
        "            # Use average of connected atoms' importance\n",
        "            bond_importance = (normalized_scores[begin_idx] + normalized_scores[end_idx]) / 2\n",
        "            if bond_importance > 0.5:  # Only highlight significant bonds\n",
        "                bonds.append(bond.GetIdx())\n",
        "\n",
        "        # Draw molecule with enhanced visualization\n",
        "        img = Draw.MolToImage(\n",
        "            mol,\n",
        "            highlightAtoms=list(range(num_atoms)),\n",
        "            highlightColor=None,\n",
        "            highlightAtomColors=atom_colors,\n",
        "            highlightBonds=bonds,  # List of bond indices\n",
        "            size=(800, 800),\n",
        "            highlightRadius=0.5\n",
        "        )\n",
        "\n",
        "        if save_path:\n",
        "            img.save(save_path)\n",
        "\n",
        "            # Create legend with enhanced gradient\n",
        "            fig, ax = plt.subplots(figsize=(8, 1))\n",
        "            gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
        "\n",
        "            # Enhanced colormap\n",
        "            colors = [(1,1,1), (1,0.5,0.5), (1,0,0)]\n",
        "            cmap = LinearSegmentedColormap.from_list(\"custom_enhanced_red\", colors, N=256)\n",
        "\n",
        "            ax.imshow(gradient, aspect='auto', cmap=cmap)\n",
        "            ax.set_xticks([0, 128, 255])\n",
        "            ax.set_xticklabels(['Low', 'Medium', 'High'])\n",
        "            ax.set_yticks([])\n",
        "            plt.title('Atom Importance Scale')\n",
        "            plt.savefig(save_path.replace('.png', '_legend.png'),\n",
        "                       bbox_inches='tight', dpi=300)\n",
        "            plt.close()\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "# Also modify the generate_explanations function to print more information:\n",
        "def generate_explanations(model, dataset, device, idx=1):\n",
        "    \"\"\"\n",
        "    Generate and visualize explanations for a specific molecule\n",
        "    \"\"\"\n",
        "    # Get specific molecule\n",
        "    graph_data = dataset[idx]\n",
        "\n",
        "    print(f\"Processing molecule {idx}\")\n",
        "    print(f\"Graph data shape - x_cat: {graph_data.x_cat.shape}, x_phys: {graph_data.x_phys.shape}\")\n",
        "\n",
        "    try:\n",
        "        # Generate SHAP explanations\n",
        "        node_importance, shap_values = explain_graph_model(\n",
        "            model,\n",
        "            graph_data,\n",
        "            device,\n",
        "            num_samples=100\n",
        "        )\n",
        "\n",
        "        print(f\"Generated node importance shape: {node_importance.shape}\")\n",
        "\n",
        "        # Get SMILES string\n",
        "        if hasattr(graph_data, 'smiles'):\n",
        "            smiles = graph_data.smiles\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            save_path = f\"molecule_explanation/molecule_explanation_{timestamp}.png\"\n",
        "\n",
        "            # Create visualization\n",
        "            fig = visualize_molecule_with_importance(\n",
        "                smiles,\n",
        "                node_importance,\n",
        "                save_path=save_path\n",
        "            )\n",
        "\n",
        "            if fig is None:\n",
        "                print(f\"Warning: Could not generate visualization for SMILES: {smiles}\")\n",
        "                return node_importance, shap_values, None\n",
        "\n",
        "            # Save the figure directly here\n",
        "            fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close(fig)  # Close the figure to free memory\n",
        "\n",
        "            return node_importance, shap_values, save_path\n",
        "        else:\n",
        "            print(\"Warning: No SMILES data found for visualization\")\n",
        "            return node_importance, shap_values, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generate_explanations: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def create_shap_style_plots(atom_info, node_importance, save_path=None):\n",
        "    \"\"\"\n",
        "    Create SHAP-style visualizations for molecular importance scores\n",
        "\n",
        "    Parameters:\n",
        "    atom_info: List of tuples (idx, symbol, raw_score, norm_score)\n",
        "    node_importance: Array of importance scores\n",
        "    save_path: Path to save the visualization\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "    try:\n",
        "        # Create a figure with multiple subplots\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # Only use the first n values from node_importance where n is the number of atoms\n",
        "        n_atoms = len(atom_info)\n",
        "        node_importance_truncated = node_importance[:n_atoms]\n",
        "\n",
        "        print(f\"Using first {n_atoms} values from node_importance\")\n",
        "\n",
        "        # 1. Summary Plot (Top)\n",
        "        ax1 = plt.subplot2grid((2, 1), (0, 0), rowspan=1)\n",
        "\n",
        "        # Create data mapping\n",
        "        data = list(zip(range(n_atoms), node_importance_truncated))\n",
        "        sorted_data = sorted(data, key=lambda x: abs(x[1]), reverse=True)\n",
        "        sorted_indices, sorted_values = zip(*sorted_data)\n",
        "\n",
        "        # Create custom colormap (red for positive values)\n",
        "        colors = [(1.0, 0.9, 0.9), (0.8, 0, 0)]\n",
        "        custom_cmap = LinearSegmentedColormap.from_list(\"custom_red\", colors)\n",
        "\n",
        "        # Plot SHAP values\n",
        "        y_pos = np.arange(len(sorted_values))\n",
        "        max_abs_val = max(abs(min(sorted_values)), abs(max(sorted_values)))\n",
        "        colors = [custom_cmap(abs(val)/max_abs_val) for val in sorted_values]\n",
        "\n",
        "        bars = ax1.barh(y_pos, sorted_values, color=colors)\n",
        "\n",
        "        # Add atom labels\n",
        "        atom_labels = []\n",
        "        for idx in sorted_indices:\n",
        "            atom = atom_info[idx]  # Get atom info for this index\n",
        "            atom_labels.append(f\"{atom[1]}{atom[0]}\")  # symbol + index\n",
        "\n",
        "        ax1.set_yticks(y_pos)\n",
        "        ax1.set_yticklabels(atom_labels)\n",
        "\n",
        "        ax1.set_xlabel('SHAP value (impact on model output)')\n",
        "        ax1.set_title('Impact of Each Atom on Model Prediction')\n",
        "\n",
        "        # Add grid for readability\n",
        "        ax1.grid(True, axis='x', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # 2. Force Plot (Bottom)\n",
        "        ax2 = plt.subplot2grid((2, 1), (1, 0), rowspan=1)\n",
        "\n",
        "        # Calculate base value (mean prediction)\n",
        "        base_value = np.mean(node_importance_truncated)\n",
        "\n",
        "        # Sort by absolute contribution\n",
        "        contributions = node_importance_truncated - base_value\n",
        "        sorted_by_contrib = sorted(zip(atom_info, contributions),\n",
        "                                 key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "        # Create force plot\n",
        "        cumsum = np.cumsum([0] + [x[1] for x in sorted_by_contrib])\n",
        "\n",
        "        # Plot connecting lines\n",
        "        for i in range(len(cumsum)-1):\n",
        "            color = 'red' if sorted_by_contrib[i][1] >= 0 else 'blue'\n",
        "            ax2.plot([cumsum[i], cumsum[i+1]], [1, 1], color=color, linewidth=2)\n",
        "\n",
        "            # Add atom labels for significant contributions\n",
        "            if abs(sorted_by_contrib[i][1]) > 0.1:  # Threshold for showing labels\n",
        "                info, contrib = sorted_by_contrib[i]\n",
        "                label = f\"{info[1]}{info[0]}\"  # symbol + index\n",
        "                y_offset = 1.1 if i % 2 == 0 else 0.9\n",
        "                ax2.annotate(f\"{label}\\n{contrib:.3f}\",\n",
        "                            xy=(cumsum[i], 1),\n",
        "                            xytext=(cumsum[i], y_offset),\n",
        "                            ha='center', va='center',\n",
        "                            arrowprops=dict(arrowstyle='->', color='gray'))\n",
        "\n",
        "        # Add base value and final prediction\n",
        "        ax2.text(base_value, 0.7, f'Base value\\n{base_value:.3f}',\n",
        "                 ha='center', va='center')\n",
        "        ax2.text(cumsum[-1], 0.7, f'Final prediction\\n{cumsum[-1]:.3f}',\n",
        "                 ha='center', va='center')\n",
        "\n",
        "        # Customize force plot\n",
        "        ax2.set_ylim(0.5, 1.5)\n",
        "        ax2.set_xlim(min(cumsum)-0.5, max(cumsum)+0.5)\n",
        "        ax2.set_title('SHAP Force Plot: How Each Atom Contributes to the Prediction')\n",
        "        ax2.set_xlabel('Model Prediction')\n",
        "        ax2.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_shap.png'),\n",
        "                        dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in create_shap_style_plots: {str(e)}\")\n",
        "        print(\"Debug info:\")\n",
        "        print(f\"Length of atom_info: {len(atom_info)}\")\n",
        "        print(f\"Length of node_importance: {len(node_importance)}\")\n",
        "        if len(atom_info) > 0:\n",
        "            print(f\"Sample atom_info entry: {atom_info[0]}\")\n",
        "        raise\n",
        "\n",
        "def create_shap_waterfall(atom_info, node_importance, save_path=None):\n",
        "    \"\"\"\n",
        "    Create a SHAP waterfall plot showing cumulative impact of atoms\n",
        "\n",
        "    Parameters:\n",
        "    atom_info: List of tuples (idx, symbol, raw_score, norm_score)\n",
        "    node_importance: Array of importance scores\n",
        "    save_path: Path to save the visualization\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    try:\n",
        "        # Only use the first n values from node_importance where n is the number of atoms\n",
        "        n_atoms = len(atom_info)\n",
        "        node_importance_truncated = node_importance[:n_atoms]\n",
        "\n",
        "        # Sort by absolute importance\n",
        "        sorted_atoms = sorted(zip(atom_info, node_importance_truncated),\n",
        "                            key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "        # Get top 10 contributors for clearer visualization\n",
        "        top_n = min(10, len(sorted_atoms))\n",
        "        sorted_atoms = sorted_atoms[:top_n]\n",
        "\n",
        "        # Calculate cumulative sums\n",
        "        values = [x[1] for x in sorted_atoms]\n",
        "        cumsum = np.cumsum([0] + values)\n",
        "\n",
        "        # Create figure\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "        # Plot waterfall\n",
        "        for i in range(len(values)):\n",
        "            # Plot vertical line\n",
        "            ax.plot([i, i], [cumsum[i], cumsum[i+1]],\n",
        "                    color='red' if values[i] >= 0 else 'blue',\n",
        "                    linewidth=2)\n",
        "\n",
        "            # Plot horizontal line\n",
        "            if i < len(values)-1:\n",
        "                ax.plot([i, i+1], [cumsum[i+1], cumsum[i+1]],\n",
        "                       color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "            # Add atom label\n",
        "            info = sorted_atoms[i][0]\n",
        "            label = f\"{info[1]}{info[0]}\"\n",
        "            ax.annotate(f\"{label}\\n{values[i]:.3f}\",\n",
        "                       xy=(i, cumsum[i+1]),\n",
        "                       xytext=(i, cumsum[i+1] + (0.05 if i % 2 == 0 else -0.05)),\n",
        "                       ha='center', va='center')\n",
        "\n",
        "        ax.set_title('SHAP Waterfall Plot: Cumulative Impact of Top Atoms')\n",
        "        ax.set_xlabel('Atoms (ordered by importance)')\n",
        "        ax.set_ylabel('Cumulative SHAP Value')\n",
        "\n",
        "        # Add grid\n",
        "        ax.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # Add explanation\n",
        "        plt.figtext(0.02, 0.02,\n",
        "                    'Red lines show positive contributions\\n'\n",
        "                    'Blue lines show negative contributions',\n",
        "                    fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_waterfall.png'),\n",
        "                        dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in create_shap_waterfall: {str(e)}\")\n",
        "        print(\"Debug info:\")\n",
        "        print(f\"Length of atom_info: {len(atom_info)}\")\n",
        "        print(f\"Length of node_importance: {len(node_importance)}\")\n",
        "        if len(atom_info) > 0:\n",
        "            print(f\"Sample atom_info entry: {atom_info[0]}\")\n",
        "        raise\n",
        "\n",
        "def create_shap_plots(atom_info, node_importance, save_path=None):\n",
        "    \"\"\"\n",
        "    Create SHAP-style visualizations with beeswarm and force plots\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "    try:\n",
        "        # Create figure with subplots\n",
        "        fig = plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Only use the first n values from node_importance where n is the number of atoms\n",
        "        n_atoms = len(atom_info)\n",
        "        node_importance_truncated = node_importance[:n_atoms]\n",
        "\n",
        "        # 1. Beeswarm-style Plot (Top)\n",
        "        ax1 = plt.subplot2grid((2, 1), (0, 0), rowspan=1)\n",
        "\n",
        "        # Sort features by absolute mean SHAP value\n",
        "        feature_order = np.argsort(np.abs(node_importance_truncated))\n",
        "\n",
        "        # Create color map similar to SHAP\n",
        "        colors = ['#ff0051', '#fa5e4f', '#f57c47', '#f1933f', '#ec9637', '#e7992f',\n",
        "                 '#e29b27', '#dcac20', '#d7be18', '#d2d011', '#c7d11b', '#bcd225',\n",
        "                 '#b2d42f', '#a7d539', '#9dd644', '#92d74e', '#87d858', '#7dd963',\n",
        "                 '#72da6d', '#67db77', '#5ddc82', '#52dd8c', '#47de96', '#3ddfb0',\n",
        "                 '#32e0ba', '#27e1c5', '#1de2cf', '#12e3d9', '#07e4e4']\n",
        "        cmap = LinearSegmentedColormap.from_list(\"shap\", colors)\n",
        "\n",
        "        # Normalize values for coloring\n",
        "        max_val = np.max(np.abs(node_importance_truncated))\n",
        "        norm_values = node_importance_truncated / max_val\n",
        "\n",
        "        # Plot dots\n",
        "        for i, idx in enumerate(feature_order):\n",
        "            value = node_importance_truncated[idx]\n",
        "            color = cmap(abs(value) / max_val)\n",
        "            # Add slight random jitter for beeswarm effect\n",
        "            jitter = np.random.normal(0, 0.02, 1)[0]\n",
        "            ax1.scatter(value, i + jitter, c=[color], alpha=0.7)\n",
        "\n",
        "        # Add feature labels\n",
        "        feature_labels = [f\"{atom_info[i][1]}{atom_info[i][0]}\" for i in feature_order]\n",
        "        ax1.set_yticks(range(len(feature_labels)))\n",
        "        ax1.set_yticklabels(feature_labels)\n",
        "\n",
        "        # Customize plot\n",
        "        ax1.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
        "        ax1.set_xlabel('SHAP value (impact on model output)')\n",
        "\n",
        "        # Add grid\n",
        "        ax1.grid(True, axis='x', linestyle='--', alpha=0.2)\n",
        "\n",
        "        # 2. Force Plot (Bottom)\n",
        "        ax2 = plt.subplot2grid((2, 1), (1, 0), rowspan=1)\n",
        "\n",
        "        # Calculate base value and contributions\n",
        "        base_value = np.mean(node_importance_truncated)\n",
        "        contributions = node_importance_truncated - base_value\n",
        "        sorted_contributions = sorted(zip(atom_info, contributions),\n",
        "                                   key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "        # Create force plot\n",
        "        cumsum = np.cumsum([0] + [x[1] for x in sorted_contributions])\n",
        "\n",
        "        # Plot segments\n",
        "        for i in range(len(cumsum)-1):\n",
        "            contrib = sorted_contributions[i][1]\n",
        "            color = '#ff0051' if contrib >= 0 else '#008bfb'  # SHAP's red/blue colors\n",
        "\n",
        "            # Draw contribution segment\n",
        "            ax2.plot([cumsum[i], cumsum[i+1]], [1, 1],\n",
        "                    color=color, linewidth=3, solid_capstyle='butt')\n",
        "\n",
        "            # Add feature labels for significant contributions\n",
        "            if abs(contrib) > 0.1:\n",
        "                info = sorted_contributions[i][0]\n",
        "                label = f\"{info[1]}{info[0]}\"\n",
        "                y_offset = 1.1 if i % 2 == 0 else 0.9\n",
        "                ax2.annotate(f\"{label}\\n{contrib:.3f}\",\n",
        "                            xy=(cumsum[i], 1),\n",
        "                            xytext=(cumsum[i], y_offset),\n",
        "                            ha='center', va='center',\n",
        "                            arrowprops=dict(arrowstyle='->', color='gray', alpha=0.5))\n",
        "\n",
        "        # Add base and final values\n",
        "        ax2.text(base_value, 0.7, f'E[f(x)]\\n{base_value:.3f}',\n",
        "                ha='center', va='center', fontsize=10,\n",
        "                bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
        "        ax2.text(cumsum[-1], 0.7, f'f(x)\\n{cumsum[-1]:.3f}',\n",
        "                ha='center', va='center', fontsize=10,\n",
        "                bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
        "\n",
        "        # Customize force plot\n",
        "        ax2.set_ylim(0.5, 1.5)\n",
        "        ax2.set_xlim(min(cumsum)-0.5, max(cumsum)+0.5)\n",
        "        ax2.set_xlabel('Model output')\n",
        "        ax2.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_shap.png'),\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in create_shap_style_plots: {str(e)}\")\n",
        "        print(\"Debug info:\")\n",
        "        print(f\"Length of atom_info: {len(atom_info)}\")\n",
        "        print(f\"Length of node_importance: {len(node_importance)}\")\n",
        "        if len(atom_info) > 0:\n",
        "            print(f\"Sample atom_info entry: {atom_info[0]}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def create_shap_visualizations(atom_info, node_importance, save_path=None):\n",
        "    \"\"\"\n",
        "    Create visualizations using SHAP's native plotting functions\n",
        "    \"\"\"\n",
        "    import shap\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    try:\n",
        "        # Get number of atoms\n",
        "        n_atoms = len(atom_info)\n",
        "        node_importance_truncated = node_importance[:n_atoms]\n",
        "\n",
        "        # Create feature matrix X\n",
        "        # Convert atom info to a pandas DataFrame\n",
        "        feature_names = [f\"{info[1]}{info[0]}\" for info in atom_info]  # Atom symbol + index\n",
        "        X = pd.DataFrame([info[2] for info in atom_info], columns=['value'])\n",
        "        X.index = feature_names\n",
        "\n",
        "        # Create SHAP values array\n",
        "        shap_values = node_importance_truncated\n",
        "\n",
        "        # Create visualizations\n",
        "\n",
        "        # 1. Summary Plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(\n",
        "            shap_values,\n",
        "            X,\n",
        "            plot_type=\"bar\",\n",
        "            show=False\n",
        "        )\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_summary.png'),\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        # 2. Waterfall Plot (for the most important atom)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.plots.waterfall(\n",
        "            shap.Explanation(\n",
        "                values=shap_values,\n",
        "                base_values=np.mean(shap_values),\n",
        "                data=X['value'].values,\n",
        "                feature_names=feature_names\n",
        "            ),\n",
        "            show=False\n",
        "        )\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_waterfall.png'),\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        # 3. Force Plot\n",
        "        force_plot = shap.force_plot(\n",
        "            base_value=np.mean(shap_values),\n",
        "            shap_values=shap_values,\n",
        "            features=X['value'].values,\n",
        "            feature_names=feature_names,\n",
        "            matplotlib=True,\n",
        "            show=False\n",
        "        )\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_force.png'),\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        # 4. Beeswarm Plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(\n",
        "            shap_values,\n",
        "            X,\n",
        "            plot_type=\"dot\",\n",
        "            show=False\n",
        "        )\n",
        "        if save_path:\n",
        "            plt.savefig(save_path.replace('.png', '_beeswarm.png'),\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"SHAP visualizations saved with prefix: {save_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in create_shap_visualizations: {str(e)}\")\n",
        "        print(\"Debug info:\")\n",
        "        print(f\"Length of atom_info: {len(atom_info)}\")\n",
        "        print(f\"Length of node_importance: {len(node_importance)}\")\n",
        "        print(f\"Feature names: {feature_names}\")\n",
        "        raise\n",
        "\n",
        "def explain_molecule_with_shap(smiles, node_importance, shap_values, save_dir='shap_explanations'):\n",
        "    \"\"\"\n",
        "    Create comprehensive SHAP visualizations for molecular analysis\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    smiles : str\n",
        "        SMILES string of the molecule\n",
        "    node_importance : numpy.ndarray\n",
        "        Importance scores for each atom\n",
        "    shap_values : numpy.ndarray\n",
        "        SHAP values for each feature\n",
        "    save_dir : str\n",
        "        Directory to save visualizations\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    shap.Explanation\n",
        "        SHAP explanation object containing all visualization data\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import shap\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from rdkit import Chem\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    try:\n",
        "        # Create save directory if it doesn't exist\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Create molecule object\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        n_atoms = mol.GetNumAtoms()\n",
        "\n",
        "        # Truncate node_importance to match number of atoms\n",
        "        node_importance = node_importance[:n_atoms]\n",
        "\n",
        "        # Create feature matrix with multiple atomic properties\n",
        "        features = []\n",
        "        feature_names = []\n",
        "        for i in range(n_atoms):\n",
        "            atom = mol.GetAtomWithIdx(i)\n",
        "            atom_features = [\n",
        "                atom.GetAtomicNum(),        # Atomic number\n",
        "                atom.GetTotalValence(),     # Valence\n",
        "                atom.GetDegree(),           # Degree\n",
        "                int(atom.GetIsAromatic()),  # Aromaticity\n",
        "                atom.GetFormalCharge()      # Formal charge\n",
        "            ]\n",
        "            features.append(atom_features)\n",
        "            symbol = atom.GetSymbol()\n",
        "            feature_names.extend([\n",
        "                f\"{symbol}{i}_AtomicNum\",\n",
        "                f\"{symbol}{i}_Valence\",\n",
        "                f\"{symbol}{i}_Degree\",\n",
        "                f\"{symbol}{i}_Aromatic\",\n",
        "                f\"{symbol}{i}_Charge\"\n",
        "            ])\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        X = np.array(features)\n",
        "        X_reshaped = X.reshape(1, -1)\n",
        "\n",
        "        # Create SHAP values matrix\n",
        "        shap_values_matrix = np.tile(node_importance[:, np.newaxis], (1, 5)).reshape(1, -1)\n",
        "\n",
        "        print(f\"\\nDebug - Data shapes:\")\n",
        "        print(f\"Feature matrix: {X.shape} -> reshaped to {X_reshaped.shape}\")\n",
        "        print(f\"SHAP values: {node_importance.shape} -> expanded to {shap_values_matrix.shape}\")\n",
        "        print(f\"Number of features: {len(feature_names)}\")\n",
        "\n",
        "        # Create explanation object\n",
        "        explanation = shap.Explanation(\n",
        "            values=shap_values_matrix,\n",
        "            base_values=np.array([np.mean(node_importance)]),\n",
        "            data=X_reshaped,\n",
        "            feature_names=feature_names\n",
        "        )\n",
        "\n",
        "        # Generate visualizations\n",
        "        plots = {\n",
        "            'summary': lambda: shap.summary_plot(\n",
        "                shap_values_matrix, X_reshaped,\n",
        "                feature_names=feature_names, show=False, plot_type=\"bar\"\n",
        "            ),\n",
        "            'bar': lambda: shap.plots.bar(explanation, show=False),\n",
        "            'waterfall': lambda: shap.plots.waterfall(explanation[0], show=False),\n",
        "            'force': lambda: shap.force_plot(\n",
        "                explanation.base_values[0], explanation.values[0],\n",
        "                X_reshaped[0], feature_names=feature_names,\n",
        "                matplotlib=True, show=False\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Save all plots\n",
        "        for plot_name, plot_func in plots.items():\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plot_func()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(save_dir, f'{plot_name}_{timestamp}_plot.png'),\n",
        "                       dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"\\nSHAP visualizations saved in directory: {save_dir}\")\n",
        "        return explanation\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in explain_molecule_with_shap: {str(e)}\")\n",
        "        print(\"\\nDebug information:\")\n",
        "        if 'X' in locals():\n",
        "            print(f\"Feature matrix shape: {X.shape}\")\n",
        "        if 'shap_values_matrix' in locals():\n",
        "            print(f\"SHAP matrix shape: {shap_values_matrix.shape}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1cbc5d",
      "metadata": {
        "id": "aa1cbc5d"
      },
      "outputs": [],
      "source": [
        "# First, let's modify your data loading code to store SMILES with each graph\n",
        "print(\"Starting data loading...\")\n",
        "extractor = MolecularFeatureExtractor()\n",
        "smiles_file = \"D:\\\\PhD\\\\Chapter3\\\\Unsupervised_GAN_Code\\\\pubchem-41-clean.txt\"\n",
        "\n",
        "dataset = []\n",
        "failed_smiles = []\n",
        "\n",
        "# Modified data loading to store SMILES\n",
        "with open(smiles_file, 'r') as f:\n",
        "    for line in f:\n",
        "        smiles = line.strip()\n",
        "        data = extractor.process_molecule(smiles)\n",
        "        if data is not None:\n",
        "            # Add SMILES as an attribute to the Data object\n",
        "            data.smiles = smiles  # Add this line\n",
        "            dataset.append(data)\n",
        "        else:\n",
        "            failed_smiles.append(smiles)\n",
        "\n",
        "print(f\"1. Loaded dataset with {len(dataset)} graphs.\")\n",
        "print(f\"2. Failed SMILES count: {len(failed_smiles)}\")\n",
        "\n",
        "if not dataset:\n",
        "    print(\"No valid graphs generated.\")\n",
        "\n",
        "# Make sure to import needed libraries\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Draw\n",
        "import traceback\n",
        "\n",
        "os.makedirs('molecule_explanation', exist_ok=True)\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "try:\n",
        "    print(\"\\nSelected molecule index: 1\")\n",
        "    node_importance, shap_values, save_path = generate_explanations(\n",
        "        encoder,\n",
        "        dataset,\n",
        "        device,\n",
        "        idx=1\n",
        "    )\n",
        "\n",
        "    if node_importance is not None and save_path is not None:\n",
        "        # Get the SMILES for the selected molecule\n",
        "        smiles = dataset[1].smiles\n",
        "\n",
        "        # Print atom mapping\n",
        "        print_atom_mapping(smiles, node_importance)\n",
        "\n",
        "        print(f\"smiles string is :\",smiles)\n",
        "        print(f\"Visualization saved as '{save_path}'\")\n",
        "\n",
        "        # Create molecule object from SMILES\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is not None:\n",
        "            # Prepare normalized scores first\n",
        "            normalized_scores = ((node_importance - node_importance.min()) /\n",
        "                              (node_importance.max() - node_importance.min()))\n",
        "\n",
        "            # Create atom_info with correct format\n",
        "            atom_info = []\n",
        "            for i in range(mol.GetNumAtoms()):\n",
        "                atom = mol.GetAtomWithIdx(i)\n",
        "                atom_info.append({\n",
        "                    'index': i,\n",
        "                    'symbol': atom.GetSymbol(),\n",
        "                    'importance': node_importance[i],\n",
        "                    'normalized': normalized_scores[i]\n",
        "                })\n",
        "\n",
        "            # Convert atom_info to the format expected by visualization functions\n",
        "            viz_atom_info = [(info['index'], info['symbol'], info['importance'], info['normalized'])\n",
        "                            for info in atom_info]\n",
        "\n",
        "            print(\"\\nPreparing SHAP visualizations...\")\n",
        "            # Create SHAP-style visualizations\n",
        "            shap_style_fig = create_shap_style_plots(viz_atom_info, node_importance, save_path)\n",
        "            waterfall_fig = create_shap_waterfall(viz_atom_info, node_importance, save_path)\n",
        "            shap_fig = create_shap_plots(viz_atom_info, node_importance, save_path)\n",
        "\n",
        "            print(f\"SHAP visualization saved as '{save_path.replace('.png', '_shap_style.png')}'\")\n",
        "            print(f\"Waterfall plot saved as '{save_path.replace('.png', '_waterfall.png')}'\")\n",
        "            print(f\"SHAP Style visualization saved as '{save_path.replace('.png', '_shap.png')}'\")\n",
        "\n",
        "            # Print some debug information\n",
        "            print(\"\\nVisualization Debug Info:\")\n",
        "            print(f\"Number of atoms in molecule: {mol.GetNumAtoms()}\")\n",
        "            print(f\"Length of node_importance: {len(node_importance)}\")\n",
        "            print(f\"Length of atom_info: {len(atom_info)}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: Could not parse SMILES: {smiles}\")\n",
        "    else:\n",
        "        print(\"Warning: No importance scores or visualization path generated\")\n",
        "\n",
        "\n",
        "\n",
        "    if node_importance is not None:\n",
        "        # Get the SMILES for the selected molecule\n",
        "        smiles = dataset[1].smiles\n",
        "\n",
        "        # Create save directory\n",
        "        save_dir = 'molecule_explanation'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Generate SHAP visualizations\n",
        "        explanation = explain_molecule_with_shap(\n",
        "            smiles,\n",
        "            node_importance,\n",
        "            shap_values,\n",
        "            save_dir=save_dir\n",
        "        )\n",
        "\n",
        "        print(\"\\nVisualization Results:\")\n",
        "        print(f\"- SHAP explanation object created\")\n",
        "        print(f\"- Base value: {explanation.base_values[0]:.4f}\")\n",
        "        print(f\"- Number of features: {len(explanation.feature_names)}\")\n",
        "        print(f\"- Visualizations saved in: {save_dir}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Warning: No importance scores generated\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError generating explanations: {e}\")\n",
        "    print(\"\\nModel architecture:\")\n",
        "    print(encoder)\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61f6299",
      "metadata": {
        "id": "d61f6299"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [torchfix]",
      "language": "python",
      "name": "torchfix"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}