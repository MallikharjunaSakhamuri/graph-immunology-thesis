{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8t2CE-XWf5r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPiflVrPWosg"
      },
      "outputs": [],
      "source": [
        "!pip install stellargraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAInvHTmFhal"
      },
      "outputs": [],
      "source": [
        "import stellargraph as sg\n",
        "from stellargraph.mapper import PaddedGraphGenerator\n",
        "from stellargraph.layer import GCNSupervisedGraphClassification\n",
        "from stellargraph import StellarGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rkZgJjAFiqY"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix,auc,precision_recall_curve,roc_curve\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy,mean_squared_error\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from stellargraph import IndexedArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KrVFrSEFlXS"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roaJbWysFm8A"
      },
      "outputs": [],
      "source": [
        "def read_para(path):\n",
        "    df = pd.read_csv(path,sep='\\t',header=None)\n",
        "    dic = {}\n",
        "    for i in range(df.shape[0]):\n",
        "        hla = df[0].iloc[i]\n",
        "        paratope = df[1].iloc[i]\n",
        "        try:\n",
        "            dic[hla] = paratope\n",
        "        except KeyError:\n",
        "            dic[hla] = []\n",
        "            dic[hla].append(paratope)\n",
        "    return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJPLF2XGFoWk"
      },
      "outputs": [],
      "source": [
        "def dict_inventory(inventory):\n",
        "    dicA, dicB, dicC = {}, {}, {}\n",
        "    dic = {'A': dicA, 'B': dicB, 'C': dicC}\n",
        "\n",
        "    for hla in inventory:\n",
        "        type_ = hla[4]  # A,B,C\n",
        "        first2 = hla[6:8]  # 01\n",
        "        last2 = hla[8:]  # 01\n",
        "        try:\n",
        "            dic[type_][first2].append(last2)\n",
        "        except KeyError:\n",
        "            dic[type_][first2] = []\n",
        "            dic[type_][first2].append(last2)\n",
        "\n",
        "    return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNlXP2GHFrMK"
      },
      "outputs": [],
      "source": [
        "def rescue_unknown_hla(hla, dic_inventory):\n",
        "    type_ = hla[4]\n",
        "    first2 = hla[6:8]\n",
        "    last2 = hla[8:]\n",
        "    big_category = dic_inventory[type_]\n",
        "    #print(hla)\n",
        "    if not big_category.get(first2) == None:\n",
        "        small_category = big_category.get(first2)\n",
        "        distance = [abs(int(last2) - int(i)) for i in small_category]\n",
        "        optimal = min(zip(small_category, distance), key=lambda x: x[1])[0]\n",
        "        return 'HLA-' + str(type_) + '*' + str(first2) + str(optimal)\n",
        "    else:\n",
        "        small_category = list(big_category.keys())\n",
        "        distance = [abs(int(first2) - int(i)) for i in small_category]\n",
        "        optimal = min(zip(small_category, distance), key=lambda x: x[1])[0]\n",
        "        return 'HLA-' + str(type_) + '*' + str(optimal) + str(big_category[optimal][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTDefDkrFtZc"
      },
      "outputs": [],
      "source": [
        "class Graph_Constructor():\n",
        "\n",
        "    @staticmethod\n",
        "    def combinator(pep,hla):\n",
        "        source = ['p' + str(i+1) for i in range(len(pep))]\n",
        "        target = ['h' + str(i+1) for i in range(len(hla))]\n",
        "        return source,target\n",
        "\n",
        "    @staticmethod\n",
        "    def numerical(pep,hla,after_pca,embed=12):   # after_pca [21,12]\n",
        "        pep = pep.replace('X','-').upper()\n",
        "        hla = hla.replace('X','-').upper()\n",
        "        feature_array_pep = np.empty([len(pep),embed])\n",
        "        feature_array_hla = np.empty([len(hla),embed])\n",
        "        amino = 'ARNDCQEGHILKMFPSTWYV-'\n",
        "        for i in range(len(pep)):\n",
        "            feature_array_pep[i,:] = after_pca[amino.index(pep[i]),:]\n",
        "        for i in range(len(hla)):\n",
        "            feature_array_hla[i,:] = after_pca[amino.index(hla[i]),:]\n",
        "        feature_array = np.concatenate([feature_array_pep,feature_array_hla],axis=0)\n",
        "        #print(feature_array_pep.shape,feature_array_hla.shape,feature_array.shape)\n",
        "        return feature_array\n",
        "\n",
        "    @staticmethod\n",
        "    def unweight_edge(pep,hla,after_pca):\n",
        "        source,target = Graph_Constructor.combinator(pep,hla)\n",
        "        combine = list(itertools.product(source,target))\n",
        "        weight = itertools.repeat(1,len(source)*len(target))\n",
        "        edges = pd.DataFrame({'source':[item[0] for item in combine],'target':[item[1] for item in combine],'weight':weight})\n",
        "        feature_array = Graph_Constructor.numerical(pep,hla,after_pca)\n",
        "        try:nodes = IndexedArray(feature_array,index=source+target)\n",
        "        except: print(pep,hla,feature_array.shape)\n",
        "        graph = StellarGraph(nodes,edges,node_type_default='corner',edge_type_default='line')\n",
        "        return graph\n",
        "\n",
        "    @staticmethod\n",
        "    def weight_anchor_edge(pep,hla,after_pca):\n",
        "        source, target = Graph_Constructor.combinator(pep, hla)\n",
        "        combine = list(itertools.product(source, target))\n",
        "        weight = itertools.repeat(1, len(source) * len(target))\n",
        "        edges = pd.DataFrame({'source': [item[0] for item in combine], 'target': [item[1] for item in combine], 'weight': weight})\n",
        "        for i in range(edges.shape[0]):\n",
        "            col1 = edges.iloc[i]['source']\n",
        "            col2 = edges.iloc[i]['target']\n",
        "            col3 = edges.iloc[i]['weight']\n",
        "            if col1 == 'a2' or col1 == 'a9' or col1 ==  'a10':\n",
        "                edges.iloc[i]['weight'] = 1.5\n",
        "        feature_array = Graph_Constructor.numerical(pep, hla, after_pca)\n",
        "        nodes = IndexedArray(feature_array, index=source + target)\n",
        "        graph = StellarGraph(nodes, edges, node_type_default='corner', edge_type_default='line')\n",
        "        return graph\n",
        "\n",
        "    @staticmethod\n",
        "    def intra_and_inter(pep,hla,after_pca):\n",
        "        source, target = Graph_Constructor.combinator(pep, hla)\n",
        "        combine = list(itertools.product(source, target))\n",
        "        weight = itertools.repeat(2, len(source) * len(target))\n",
        "        edges_inter = pd.DataFrame({'source': [item[0] for item in combine], 'target': [item[1] for item in combine], 'weight': weight})\n",
        "        intra_pep = list(itertools.combinations(source,2))\n",
        "        intra_hla = list(itertools.combinations(target,2))\n",
        "        intra = intra_pep + intra_hla\n",
        "        weight = itertools.repeat(1,len(intra))\n",
        "        edges_intra = pd.DataFrame({'source':[item[0] for item in intra],'target':[item[1] for item in intra],'weight':weight})\n",
        "        edges = pd.concat([edges_inter,edges_intra])\n",
        "        edges = edges.set_index(pd.Index(np.arange(edges.shape[0])))\n",
        "        feature_array = Graph_Constructor.numerical(pep, hla, after_pca)\n",
        "        nodes = IndexedArray(feature_array, index=source + target)\n",
        "        graph = StellarGraph(nodes, edges, node_type_default='corner', edge_type_default='line')\n",
        "        return graph\n",
        "\n",
        "    @staticmethod\n",
        "    def entrance(df,after_pca,hla_dic,dic_inventory):\n",
        "        graphs = []\n",
        "        graph_labels = []\n",
        "        for i in range(df.shape[0]):\n",
        "            print(i)\n",
        "            pep = df['peptide'].iloc[i]\n",
        "            try:\n",
        "                hla = hla_dic[df['HLA'].iloc[i]]\n",
        "            except KeyError:\n",
        "                hla = hla_dic[rescue_unknown_hla(df['HLA'].iloc[i],dic_inventory)]\n",
        "            label = df['immunogenicity'].iloc[i]\n",
        "            #if label != 'Negative': label = 0\n",
        "            #else: label = 1\n",
        "            #graph = Graph_Constructor.unweight_edge(pep,hla,after_pca)\n",
        "            #graph = Graph_Constructor.unweight_edge(pep,hla,after_pca)\n",
        "            graph = Graph_Constructor.intra_and_inter(pep,hla,after_pca)\n",
        "            graphs.append(graph)\n",
        "            graph_labels.append(label)\n",
        "        graph_labels = pd.Series(graph_labels)\n",
        "        return graphs,graph_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seeKiegpFv4a"
      },
      "outputs": [],
      "source": [
        "def train_fold(model, train_gen, test_gen, es, epochs):\n",
        "    history = model.fit(\n",
        "        train_gen, epochs=epochs, validation_data=test_gen, verbose=2, callbacks=[es],)\n",
        "    # calculate performance on the test data and return along with history\n",
        "    test_metrics = model.evaluate(test_gen, verbose=0)\n",
        "    test_acc = test_metrics[model.metrics_names.index(\"acc\")]\n",
        "    return history, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1umwI2WPFxbz"
      },
      "outputs": [],
      "source": [
        "def get_generators(train_index, test_index, graph_labels, batch_size):\n",
        "    train_gen = generator.flow(\n",
        "        train_index, targets=graph_labels.iloc[train_index].values, batch_size=batch_size)\n",
        "    test_gen = generator.flow(\n",
        "        test_index, targets=graph_labels.iloc[test_index].values, batch_size=batch_size)\n",
        "\n",
        "    return train_gen, test_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOpd2LEkFzaS"
      },
      "outputs": [],
      "source": [
        "def draw_ROC(y_true,y_pred):\n",
        "\n",
        "    fpr,tpr,_ = roc_curve(y_true,y_pred,pos_label=1)\n",
        "    area_mine = auc(fpr,tpr)\n",
        "    fig = plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',\n",
        "            lw=lw, label='ROC curve (area = %0.2f)' % area_mine)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KqFSmalF3kw"
      },
      "outputs": [],
      "source": [
        "def draw_PR(y_true,y_pred):\n",
        "    precision,recall,_ = precision_recall_curve(y_true,y_pred,pos_label=1)\n",
        "    area_PR = auc(recall,precision)\n",
        "    baseline = np.sum(np.array(y_true) == 1) / len(y_true)\n",
        "\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(recall,precision, color='darkorange',\n",
        "            lw=lw, label='PR curve (area = %0.2f)' % area_PR)\n",
        "    plt.plot([0, 1], [baseline, baseline], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('PR curve example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtIw24_XF6PY"
      },
      "outputs": [],
      "source": [
        "def draw_history(history):\n",
        "    plt.subplot(211)\n",
        "    plt.title('Loss')\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.legend()\n",
        "    # plot accuracy during training\n",
        "    plt.subplot(212)\n",
        "    plt.title('Accuracy')\n",
        "    plt.plot(history.history['acc'], label='train')\n",
        "    plt.plot(history.history['val_acc'], label='validation')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdiCZWNnGjkl"
      },
      "outputs": [],
      "source": [
        "def hla_df_to_dic(hla):\n",
        "    dic = {}\n",
        "    for i in range(hla.shape[0]):\n",
        "        col1 = hla['HLA'].iloc[i]  # HLA allele\n",
        "        col2 = hla['pseudo'].iloc[i]  # pseudo sequence\n",
        "        dic[col1] = col2\n",
        "    return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2gs8Z53Glcq"
      },
      "outputs": [],
      "source": [
        "def retain_910(ori):\n",
        "    cond = []\n",
        "    for i in range(ori.shape[0]):\n",
        "        peptide = ori['peptide'].iloc[i]\n",
        "        if len(peptide) == 9 or len(peptide) == 10:\n",
        "            cond.append(True)\n",
        "        else:\n",
        "            cond.append(False)\n",
        "    data = ori.loc[cond]\n",
        "    data = data.set_index(pd.Index(np.arange(data.shape[0])))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnTsnL1LGnwn"
      },
      "outputs": [],
      "source": [
        "    ori_train = pd.read_csv('remove0123_sample100.csv')\n",
        "    hla = pd.read_csv('hla2paratopeTable_aligned.txt',sep='\\t')\n",
        "    after_pca = np.loadtxt('after_pca.txt')\n",
        "    hla_dic = hla_df_to_dic(hla)\n",
        "    inventory = list(hla_dic.keys())\n",
        "    dic_inventory = dict_inventory(inventory)\n",
        "\n",
        "    ori_train['immunogenicity'], ori_train['potential'] = ori_train['potential'], ori_train['immunogenicity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI9y8gWrGpbP"
      },
      "outputs": [],
      "source": [
        "graphs, graph_labels = Graph_Constructor.entrance(ori_train, after_pca, hla_dic, dic_inventory)\n",
        "generator = PaddedGraphGenerator(graphs=graphs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj53-GJuGtJm"
      },
      "outputs": [],
      "source": [
        "gc_model = GCNSupervisedGraphClassification(\n",
        "            layer_sizes=[64, 64],\n",
        "            activations=[\"relu\", \"relu\"],\n",
        "            generator=generator,\n",
        "            dropout=0.2, )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHhJWl8gGvYQ"
      },
      "outputs": [],
      "source": [
        "x_inp, x_out = gc_model.in_out_tensors()\n",
        "predictions = Dense(units=32, activation=\"relu\")(x_out)\n",
        "predictions = Dense(units=16, activation=\"relu\")(predictions)\n",
        "predictions = Dense(units=1, activation=\"sigmoid\")(predictions)\n",
        "model = Model(inputs=x_inp, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IoWaQK0GzC1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(0.001), loss=mean_squared_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmd43k_yG2_w"
      },
      "outputs": [],
      "source": [
        "train_index, test_index = model_selection.train_test_split(ori_train.index, train_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcPH8B1GG_GU"
      },
      "outputs": [],
      "source": [
        "def get_generators1(train_index, test_index, graph_labels):\n",
        "    train_gen = generator.flow(\n",
        "        train_index, targets=graph_labels.iloc[train_index].values)\n",
        "    test_gen = generator.flow(\n",
        "        test_index, targets=graph_labels.iloc[test_index].values)\n",
        "\n",
        "    return train_gen, test_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhOmhvEVHJqJ"
      },
      "outputs": [],
      "source": [
        "!pip install networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IPSjk5NHU4S"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCtpbuXOHRn9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(graphs, graph_labels, test_size = 0.33, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rjf5i3xHJCQ"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zJkeWZKHaG9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import stellargraph as sg\n",
        "from stellargraph.mapper import PaddedGraphGenerator\n",
        "from stellargraph.layer import DeepGraphCNN\n",
        "from stellargraph import StellarGraph\n",
        "\n",
        "from stellargraph import datasets\n",
        "\n",
        "from sklearn import model_selection\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-1AHKf6HglI"
      },
      "outputs": [],
      "source": [
        "summary = pd.DataFrame(\n",
        "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
        "    columns=[\"nodes\", \"edges\"],\n",
        ")\n",
        "summary.describe().round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GafZpCJrHhDn"
      },
      "outputs": [],
      "source": [
        "graph_labels.value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFur10p5HmCT"
      },
      "outputs": [],
      "source": [
        "graph_labels = pd.get_dummies(graph_labels, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3b5uIFgML3y"
      },
      "outputs": [],
      "source": [
        "ori_train1 = ori_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svTOiezNJY5x"
      },
      "outputs": [],
      "source": [
        "ori_train1.loc[ori_train1[\"potential\"] != \"Negative\", \"potential\"] = 'Positive'\n",
        "ori_train1['potential'] = ori_train1['potential'].astype('category')\n",
        "ori_train1['potential'] = pd.factorize(ori_train1['potential'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdD-1j6JJeP-"
      },
      "outputs": [],
      "source": [
        "graph_labels = ori_train1['potential']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS8wGMx8LEdJ"
      },
      "outputs": [],
      "source": [
        "graph_labels.value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miczOwrlHpll"
      },
      "outputs": [],
      "source": [
        "generator = PaddedGraphGenerator(graphs=graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z7bBviaVAyn"
      },
      "source": [
        "Deep CGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeTbT8cdHrnZ"
      },
      "outputs": [],
      "source": [
        "k = 35  # the number of rows for the output tensor\n",
        "layer_sizes = [32, 32, 32, 1]\n",
        "\n",
        "dgcnn_model = DeepGraphCNN(\n",
        "    layer_sizes=layer_sizes,\n",
        "    activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
        "    k=k,\n",
        "    bias=False,\n",
        "    generator=generator,\n",
        ")\n",
        "x_inp, x_out = dgcnn_model.in_out_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pbiy8mNIHdD"
      },
      "outputs": [],
      "source": [
        "x_out = Conv1D(filters=16, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
        "x_out = MaxPool1D(pool_size=2)(x_out)\n",
        "\n",
        "x_out = Conv1D(filters=32, kernel_size=5, strides=1)(x_out)\n",
        "\n",
        "x_out = Flatten()(x_out)\n",
        "\n",
        "x_out = Dense(units=128, activation=\"relu\")(x_out)\n",
        "x_out = Dropout(rate=0.5)(x_out)\n",
        "\n",
        "predictions = Dense(units=1, activation=\"sigmoid\")(x_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4_aR-93IKoE"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=x_inp, outputs=predictions)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=0.0001), loss=binary_crossentropy, metrics=[\"acc\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_MInNMbINkD"
      },
      "outputs": [],
      "source": [
        "train_graphs, test_graphs = model_selection.train_test_split(\n",
        "    graph_labels, train_size=0.9, test_size=None, stratify=graph_labels,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD3ggoDCIQhc"
      },
      "outputs": [],
      "source": [
        "gen = PaddedGraphGenerator(graphs=graphs)\n",
        "\n",
        "train_gen = gen.flow(\n",
        "    list(train_graphs.index - 1),\n",
        "    targets=train_graphs.values,\n",
        "    batch_size=50,\n",
        "    symmetric_normalization=False,\n",
        ")\n",
        "\n",
        "test_gen = gen.flow(\n",
        "    list(test_graphs.index - 1),\n",
        "    targets=test_graphs.values,\n",
        "    batch_size=1,\n",
        "    symmetric_normalization=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf2Tk94oITx_"
      },
      "outputs": [],
      "source": [
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsQEP7w9IUUZ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_gen, epochs=epochs, verbose=1, validation_data=test_gen, shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qivFvRgcIYaN"
      },
      "outputs": [],
      "source": [
        "sg.utils.plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyMiv_CTI7o5"
      },
      "outputs": [],
      "source": [
        "test_metrics = model.evaluate(test_gen)\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for name, val in zip(model.metrics_names, test_metrics):\n",
        "    print(\"\\t{}: {:0.4f}\".format(name, val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyNNFNeDHjvx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}